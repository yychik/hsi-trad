{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction As Classification\n",
    "Continuing the 2800-HK price prediction from classification perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Modules and load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import sklearn\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Keras module\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pretty plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>P_L1</th>\n",
       "      <th>P_L2</th>\n",
       "      <th>P_L3</th>\n",
       "      <th>P_L4</th>\n",
       "      <th>P_L5</th>\n",
       "      <th>P_L6</th>\n",
       "      <th>P_L7</th>\n",
       "      <th>P_L8</th>\n",
       "      <th>P_L9</th>\n",
       "      <th>...</th>\n",
       "      <th>P_L11</th>\n",
       "      <th>P_L12</th>\n",
       "      <th>P_L13</th>\n",
       "      <th>P_L14</th>\n",
       "      <th>P_L15</th>\n",
       "      <th>P_L16</th>\n",
       "      <th>P_L17</th>\n",
       "      <th>P_L18</th>\n",
       "      <th>P_L19</th>\n",
       "      <th>P_L20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-08-31</th>\n",
       "      <td>24.35</td>\n",
       "      <td>23.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.35</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.85</td>\n",
       "      <td>...</td>\n",
       "      <td>20.95</td>\n",
       "      <td>21.70</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.25</td>\n",
       "      <td>22.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-03</th>\n",
       "      <td>24.30</td>\n",
       "      <td>24.35</td>\n",
       "      <td>23.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.35</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.05</td>\n",
       "      <td>...</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.95</td>\n",
       "      <td>21.70</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-04</th>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.35</td>\n",
       "      <td>23.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.35</td>\n",
       "      <td>22.70</td>\n",
       "      <td>...</td>\n",
       "      <td>21.85</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.95</td>\n",
       "      <td>21.70</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-05</th>\n",
       "      <td>24.35</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.35</td>\n",
       "      <td>23.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.35</td>\n",
       "      <td>...</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.85</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.95</td>\n",
       "      <td>21.70</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-06</th>\n",
       "      <td>24.50</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.35</td>\n",
       "      <td>23.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.30</td>\n",
       "      <td>...</td>\n",
       "      <td>22.70</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.85</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.95</td>\n",
       "      <td>21.70</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                P   P_L1   P_L2   P_L3   P_L4   P_L5   P_L6   P_L7   P_L8  \\\n",
       "Date                                                                        \n",
       "2007-08-31  24.35  23.80  23.35  23.70  23.90  23.30  23.35  22.70  22.05   \n",
       "2007-09-03  24.30  24.35  23.80  23.35  23.70  23.90  23.30  23.35  22.70   \n",
       "2007-09-04  24.30  24.30  24.35  23.80  23.35  23.70  23.90  23.30  23.35   \n",
       "2007-09-05  24.35  24.30  24.30  24.35  23.80  23.35  23.70  23.90  23.30   \n",
       "2007-09-06  24.50  24.35  24.30  24.30  24.35  23.80  23.35  23.70  23.90   \n",
       "\n",
       "             P_L9  ...    P_L11  P_L12  P_L13  P_L14  P_L15  P_L16  P_L17  \\\n",
       "Date               ...                                                      \n",
       "2007-08-31  21.85  ...    20.95  21.70  22.35  22.30  22.05  22.70  22.85   \n",
       "2007-09-03  22.05  ...    20.80  20.95  21.70  22.35  22.30  22.05  22.70   \n",
       "2007-09-04  22.70  ...    21.85  20.80  20.95  21.70  22.35  22.30  22.05   \n",
       "2007-09-05  23.35  ...    22.05  21.85  20.80  20.95  21.70  22.35  22.30   \n",
       "2007-09-06  23.30  ...    22.70  22.05  21.85  20.80  20.95  21.70  22.35   \n",
       "\n",
       "            P_L18  P_L19  P_L20  \n",
       "Date                             \n",
       "2007-08-31  22.15  22.25  22.85  \n",
       "2007-09-03  22.85  22.15  22.25  \n",
       "2007-09-04  22.70  22.85  22.15  \n",
       "2007-09-05  22.05  22.70  22.85  \n",
       "2007-09-06  22.30  22.05  22.70  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import price data\n",
    "#Load the historical prices of 2800-HK, with lags 1 to lag 20\n",
    "price_hist_data = pd.read_csv('price_only.csv', skiprows=1, parse_dates=['Date']).set_index(['Date'])\n",
    "price_hist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Bid</th>\n",
       "      <th>20D Vol</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA15</th>\n",
       "      <th>MA12</th>\n",
       "      <th>MA20</th>\n",
       "      <th>...</th>\n",
       "      <th>DY_LTM</th>\n",
       "      <th>DY_NTM</th>\n",
       "      <th>ADV_VOL</th>\n",
       "      <th>PAYOUT</th>\n",
       "      <th>ANALYST_SENTIMENT</th>\n",
       "      <th>EPS_GRW_FY1</th>\n",
       "      <th>EPS_GRW_FY2</th>\n",
       "      <th>PE_NTM</th>\n",
       "      <th>PE_LTM</th>\n",
       "      <th>C2D_LTM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-08-31</th>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>2.367823</td>\n",
       "      <td>23.82</td>\n",
       "      <td>22.841667</td>\n",
       "      <td>22.696667</td>\n",
       "      <td>22.6225</td>\n",
       "      <td>...</td>\n",
       "      <td>2.782797</td>\n",
       "      <td>2.880128</td>\n",
       "      <td>99.419898</td>\n",
       "      <td>48.051962</td>\n",
       "      <td>1.909071</td>\n",
       "      <td>30.724490</td>\n",
       "      <td>2.717280</td>\n",
       "      <td>16.695058</td>\n",
       "      <td>16.975805</td>\n",
       "      <td>58.050474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-03</th>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>2.266743</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.120832</td>\n",
       "      <td>22.830000</td>\n",
       "      <td>22.7250</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784563</td>\n",
       "      <td>2.892308</td>\n",
       "      <td>11.570023</td>\n",
       "      <td>48.305678</td>\n",
       "      <td>1.835359</td>\n",
       "      <td>31.005439</td>\n",
       "      <td>1.876752</td>\n",
       "      <td>16.709085</td>\n",
       "      <td>16.925571</td>\n",
       "      <td>58.154835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-04</th>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>24.30</td>\n",
       "      <td>2.259649</td>\n",
       "      <td>24.02</td>\n",
       "      <td>23.412500</td>\n",
       "      <td>22.960000</td>\n",
       "      <td>22.8325</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784339</td>\n",
       "      <td>2.894377</td>\n",
       "      <td>69.555725</td>\n",
       "      <td>48.307102</td>\n",
       "      <td>1.725886</td>\n",
       "      <td>31.040968</td>\n",
       "      <td>1.891823</td>\n",
       "      <td>16.697662</td>\n",
       "      <td>16.919413</td>\n",
       "      <td>58.177640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-05</th>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>24.35</td>\n",
       "      <td>2.172140</td>\n",
       "      <td>24.22</td>\n",
       "      <td>23.620832</td>\n",
       "      <td>23.136667</td>\n",
       "      <td>22.9075</td>\n",
       "      <td>...</td>\n",
       "      <td>2.767348</td>\n",
       "      <td>2.867314</td>\n",
       "      <td>24.265623</td>\n",
       "      <td>48.267351</td>\n",
       "      <td>1.741908</td>\n",
       "      <td>30.716929</td>\n",
       "      <td>1.878484</td>\n",
       "      <td>16.841225</td>\n",
       "      <td>17.017692</td>\n",
       "      <td>58.195446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-06</th>\n",
       "      <td>24.50</td>\n",
       "      <td>24.50</td>\n",
       "      <td>24.50</td>\n",
       "      <td>24.50</td>\n",
       "      <td>24.50</td>\n",
       "      <td>2.160638</td>\n",
       "      <td>24.36</td>\n",
       "      <td>23.825000</td>\n",
       "      <td>23.373333</td>\n",
       "      <td>22.9975</td>\n",
       "      <td>...</td>\n",
       "      <td>2.775339</td>\n",
       "      <td>2.878880</td>\n",
       "      <td>88.845002</td>\n",
       "      <td>48.288397</td>\n",
       "      <td>1.696151</td>\n",
       "      <td>31.336520</td>\n",
       "      <td>1.861943</td>\n",
       "      <td>16.780660</td>\n",
       "      <td>16.975485</td>\n",
       "      <td>58.224743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close   High    Low    Ask    Bid   20D Vol    MA5       MA15  \\\n",
       "Date                                                                        \n",
       "2007-08-31  24.35  24.35  24.35  24.35  24.35  2.367823  23.82  22.841667   \n",
       "2007-09-03  24.30  24.30  24.30  24.30  24.30  2.266743  23.90  23.120832   \n",
       "2007-09-04  24.30  24.30  24.30  24.30  24.30  2.259649  24.02  23.412500   \n",
       "2007-09-05  24.35  24.35  24.35  24.35  24.35  2.172140  24.22  23.620832   \n",
       "2007-09-06  24.50  24.50  24.50  24.50  24.50  2.160638  24.36  23.825000   \n",
       "\n",
       "                 MA12     MA20    ...        DY_LTM    DY_NTM    ADV_VOL  \\\n",
       "Date                              ...                                      \n",
       "2007-08-31  22.696667  22.6225    ...      2.782797  2.880128  99.419898   \n",
       "2007-09-03  22.830000  22.7250    ...      2.784563  2.892308  11.570023   \n",
       "2007-09-04  22.960000  22.8325    ...      2.784339  2.894377  69.555725   \n",
       "2007-09-05  23.136667  22.9075    ...      2.767348  2.867314  24.265623   \n",
       "2007-09-06  23.373333  22.9975    ...      2.775339  2.878880  88.845002   \n",
       "\n",
       "               PAYOUT  ANALYST_SENTIMENT  EPS_GRW_FY1  EPS_GRW_FY2     PE_NTM  \\\n",
       "Date                                                                            \n",
       "2007-08-31  48.051962           1.909071    30.724490     2.717280  16.695058   \n",
       "2007-09-03  48.305678           1.835359    31.005439     1.876752  16.709085   \n",
       "2007-09-04  48.307102           1.725886    31.040968     1.891823  16.697662   \n",
       "2007-09-05  48.267351           1.741908    30.716929     1.878484  16.841225   \n",
       "2007-09-06  48.288397           1.696151    31.336520     1.861943  16.780660   \n",
       "\n",
       "               PE_LTM    C2D_LTM  \n",
       "Date                              \n",
       "2007-08-31  16.975805  58.050474  \n",
       "2007-09-03  16.925571  58.154835  \n",
       "2007-09-04  16.919413  58.177640  \n",
       "2007-09-05  17.017692  58.195446  \n",
       "2007-09-06  16.975485  58.224743  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Fundamentals Data\n",
    "fund_data = pd.read_csv('new_index_data.csv', skiprows=1, parse_dates=['Date']).set_index(['Date'])\n",
    "fund_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hang Seng Index</th>\n",
       "      <th>SSE Composite Index</th>\n",
       "      <th>ASX All Ordinaries</th>\n",
       "      <th>India S&amp;P BSE SENSEX</th>\n",
       "      <th>TOPIX</th>\n",
       "      <th>KOSPI Composite Index</th>\n",
       "      <th>Taiwan TAIEX</th>\n",
       "      <th>FTSE Bursa Malaysia KLCI</th>\n",
       "      <th>FTSE Straits Times Index</th>\n",
       "      <th>Philippines PSE PSEi</th>\n",
       "      <th>...</th>\n",
       "      <th>Turkey BIST 100</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>DJ Industrial Average</th>\n",
       "      <th>Colombia IGBC</th>\n",
       "      <th>Canada S&amp;P/TSX Composite</th>\n",
       "      <th>Brazil Bovespa Index</th>\n",
       "      <th>Mexico IPC</th>\n",
       "      <th>Israel TA-125</th>\n",
       "      <th>Saudi Arabia All Share (TASI)</th>\n",
       "      <th>FTSE JSE All Share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-08-31</th>\n",
       "      <td>23984.14</td>\n",
       "      <td>5218.825</td>\n",
       "      <td>6248.3</td>\n",
       "      <td>15318.60</td>\n",
       "      <td>1608.25</td>\n",
       "      <td>1873.24</td>\n",
       "      <td>8982.16</td>\n",
       "      <td>1273.93</td>\n",
       "      <td>3328.43</td>\n",
       "      <td>3365.29</td>\n",
       "      <td>...</td>\n",
       "      <td>50198.60</td>\n",
       "      <td>1473.99</td>\n",
       "      <td>13357.74</td>\n",
       "      <td>10728.74</td>\n",
       "      <td>13660.48</td>\n",
       "      <td>54637.24</td>\n",
       "      <td>30347.86</td>\n",
       "      <td>1034.67</td>\n",
       "      <td>8226.97</td>\n",
       "      <td>28660.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-03</th>\n",
       "      <td>23904.09</td>\n",
       "      <td>5321.055</td>\n",
       "      <td>6272.5</td>\n",
       "      <td>15422.05</td>\n",
       "      <td>1605.44</td>\n",
       "      <td>1881.81</td>\n",
       "      <td>8979.96</td>\n",
       "      <td>1284.14</td>\n",
       "      <td>3321.36</td>\n",
       "      <td>3369.14</td>\n",
       "      <td>...</td>\n",
       "      <td>49936.94</td>\n",
       "      <td>1473.99</td>\n",
       "      <td>13357.74</td>\n",
       "      <td>10750.79</td>\n",
       "      <td>13660.48</td>\n",
       "      <td>54832.51</td>\n",
       "      <td>30797.60</td>\n",
       "      <td>1047.33</td>\n",
       "      <td>8017.54</td>\n",
       "      <td>28887.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-04</th>\n",
       "      <td>23886.07</td>\n",
       "      <td>5294.045</td>\n",
       "      <td>6297.1</td>\n",
       "      <td>15465.40</td>\n",
       "      <td>1596.74</td>\n",
       "      <td>1874.74</td>\n",
       "      <td>8922.98</td>\n",
       "      <td>1283.75</td>\n",
       "      <td>3308.81</td>\n",
       "      <td>3312.30</td>\n",
       "      <td>...</td>\n",
       "      <td>50032.59</td>\n",
       "      <td>1489.42</td>\n",
       "      <td>13448.86</td>\n",
       "      <td>10880.85</td>\n",
       "      <td>13755.23</td>\n",
       "      <td>55250.47</td>\n",
       "      <td>30932.71</td>\n",
       "      <td>1054.69</td>\n",
       "      <td>7878.70</td>\n",
       "      <td>29051.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-05</th>\n",
       "      <td>24069.17</td>\n",
       "      <td>5310.716</td>\n",
       "      <td>6274.3</td>\n",
       "      <td>15446.15</td>\n",
       "      <td>1569.47</td>\n",
       "      <td>1865.59</td>\n",
       "      <td>8913.85</td>\n",
       "      <td>1297.93</td>\n",
       "      <td>3375.02</td>\n",
       "      <td>3342.35</td>\n",
       "      <td>...</td>\n",
       "      <td>49421.38</td>\n",
       "      <td>1472.29</td>\n",
       "      <td>13305.47</td>\n",
       "      <td>10819.91</td>\n",
       "      <td>13683.28</td>\n",
       "      <td>54407.83</td>\n",
       "      <td>30809.55</td>\n",
       "      <td>1048.70</td>\n",
       "      <td>7853.66</td>\n",
       "      <td>28696.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-06</th>\n",
       "      <td>24050.40</td>\n",
       "      <td>5393.660</td>\n",
       "      <td>6265.3</td>\n",
       "      <td>15616.31</td>\n",
       "      <td>1568.52</td>\n",
       "      <td>1888.81</td>\n",
       "      <td>9017.08</td>\n",
       "      <td>1298.85</td>\n",
       "      <td>3399.49</td>\n",
       "      <td>3326.53</td>\n",
       "      <td>...</td>\n",
       "      <td>49601.39</td>\n",
       "      <td>1478.55</td>\n",
       "      <td>13363.35</td>\n",
       "      <td>10844.40</td>\n",
       "      <td>13795.69</td>\n",
       "      <td>54569.00</td>\n",
       "      <td>30816.95</td>\n",
       "      <td>1033.23</td>\n",
       "      <td>7853.66</td>\n",
       "      <td>28850.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hang Seng Index  SSE Composite Index  ASX All Ordinaries  \\\n",
       "Date                                                                   \n",
       "2007-08-31         23984.14             5218.825              6248.3   \n",
       "2007-09-03         23904.09             5321.055              6272.5   \n",
       "2007-09-04         23886.07             5294.045              6297.1   \n",
       "2007-09-05         24069.17             5310.716              6274.3   \n",
       "2007-09-06         24050.40             5393.660              6265.3   \n",
       "\n",
       "            India S&P BSE SENSEX    TOPIX  KOSPI Composite Index  \\\n",
       "Date                                                               \n",
       "2007-08-31              15318.60  1608.25                1873.24   \n",
       "2007-09-03              15422.05  1605.44                1881.81   \n",
       "2007-09-04              15465.40  1596.74                1874.74   \n",
       "2007-09-05              15446.15  1569.47                1865.59   \n",
       "2007-09-06              15616.31  1568.52                1888.81   \n",
       "\n",
       "            Taiwan TAIEX  FTSE Bursa Malaysia KLCI  FTSE Straits Times Index  \\\n",
       "Date                                                                           \n",
       "2007-08-31       8982.16                   1273.93                   3328.43   \n",
       "2007-09-03       8979.96                   1284.14                   3321.36   \n",
       "2007-09-04       8922.98                   1283.75                   3308.81   \n",
       "2007-09-05       8913.85                   1297.93                   3375.02   \n",
       "2007-09-06       9017.08                   1298.85                   3399.49   \n",
       "\n",
       "            Philippines PSE PSEi         ...          Turkey BIST 100  \\\n",
       "Date                                     ...                            \n",
       "2007-08-31               3365.29         ...                 50198.60   \n",
       "2007-09-03               3369.14         ...                 49936.94   \n",
       "2007-09-04               3312.30         ...                 50032.59   \n",
       "2007-09-05               3342.35         ...                 49421.38   \n",
       "2007-09-06               3326.53         ...                 49601.39   \n",
       "\n",
       "            S&P 500  DJ Industrial Average  Colombia IGBC  \\\n",
       "Date                                                        \n",
       "2007-08-31  1473.99               13357.74       10728.74   \n",
       "2007-09-03  1473.99               13357.74       10750.79   \n",
       "2007-09-04  1489.42               13448.86       10880.85   \n",
       "2007-09-05  1472.29               13305.47       10819.91   \n",
       "2007-09-06  1478.55               13363.35       10844.40   \n",
       "\n",
       "            Canada S&P/TSX Composite  Brazil Bovespa Index  Mexico IPC  \\\n",
       "Date                                                                     \n",
       "2007-08-31                  13660.48              54637.24    30347.86   \n",
       "2007-09-03                  13660.48              54832.51    30797.60   \n",
       "2007-09-04                  13755.23              55250.47    30932.71   \n",
       "2007-09-05                  13683.28              54407.83    30809.55   \n",
       "2007-09-06                  13795.69              54569.00    30816.95   \n",
       "\n",
       "            Israel TA-125  Saudi Arabia All Share (TASI)  FTSE JSE All Share  \n",
       "Date                                                                          \n",
       "2007-08-31        1034.67                        8226.97            28660.35  \n",
       "2007-09-03        1047.33                        8017.54            28887.48  \n",
       "2007-09-04        1054.69                        7878.70            29051.96  \n",
       "2007-09-05        1048.70                        7853.66            28696.67  \n",
       "2007-09-06        1033.23                        7853.66            28850.19  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Global index data\n",
    "idx_data = pd.read_csv('indices.csv', skiprows=1, parse_dates=['Date']).set_index(['Date'])\n",
    "idx_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pre-process Raw Data\n",
    "1. Generate labels\n",
    "2. Apply lags to global index data\n",
    "3. Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate Labels from Price History Data\n",
    "#Generate UP/DOWN labels from log change\n",
    "cutoff_perc = 0.0005 #0.05% return as cuttoff to define UP label\n",
    "lag = 1 #forward returns\n",
    "\n",
    "labels = np.zeros([price_hist_data.shape[0]])\n",
    "\n",
    "#Caluclate log-returns\n",
    "ret = np.log(price_hist_data['P'].shift(-lag)/price_hist_data['P'])\n",
    "labels = [1 if r > cutoff_perc else 0 for r in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applying lags to index data\n",
    "#Seperate the indices into 2 classes - lag or no_lag\n",
    "no_lag = [0, 1, 2, 4, 5, 6, 9, 10]\n",
    "lag = [i for i in range(0,idx_data.shape[1]) if i not in no_lag]\n",
    "\n",
    "#Processing the dataset by applying appropriate lags\n",
    "lagged_data = idx_data.iloc[:,lag].shift(1)\n",
    "idx_data = pd.concat([idx_data.iloc[:,no_lag], lagged_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove first row\n",
    "idx_data = idx_data.iloc[1:, :]\n",
    "price_hist_data = price_hist_data.iloc[1:, :]\n",
    "fund_data = fund_data.iloc[1:, :]\n",
    "labels=labels[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of idx_data:  (2483, 42)\n",
      "Shape of price_hist_data:  (2483, 21)\n",
      "Shape of fund_data:  (2483, 30)\n",
      "Shape of labels:  2483\n"
     ]
    }
   ],
   "source": [
    "#Check Dimensions to make sure everythings right before continuing..\n",
    "print(\"Shape of idx_data: \", idx_data.shape)\n",
    "print(\"Shape of price_hist_data: \", price_hist_data.shape)\n",
    "print(\"Shape of fund_data: \", fund_data.shape)\n",
    "print(\"Shape of labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training data\n",
    "X = np.array(pd.concat([price_hist_data, idx_data, fund_data], axis=1))\n",
    "y = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking whether there are NAs\n",
    "[np.sum(np.isnan(X), axis=0) > 0] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split training, validation and test set\n",
    "\n",
    "In this stage we have a look-ahead bias free set of data (X) and the labels y. Next, we will need to:\n",
    "- Normalize the input data. To avoid look ahead bias, we will z-score the features, using ONLY the training set.\n",
    "- Next, generate input data into LSTM network. We will need an overlapping sequence at 1-day window as input samples. Specifically suppose the *timestep* is 240, we will have a list of array consists of *number of rows of X* - 240 entries, each element has dimentions (240, num_of_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to split raw data into training, validation and test set, returns a numpy array.\n",
    "def split_data(input_data=[], train_size=0.8, val_size=0.2, test_size=0):\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    #PARAM: input_data: numpy nd array\n",
    "    #PARAM: training_size: size of training set in decimal\n",
    "    #PARAM: val_size: size of validation set in decimal\n",
    "    #PARAM: test_size: size of test set in decimal\n",
    "    #OUTPUT: tuple (train_set, validation_set, test_set)\n",
    "    #------------------------------------------------\n",
    "    \n",
    "    #First check whether traing_size + val_size + test_size = 1 and each of the entries are positive\n",
    "    assert(train_size + val_size + test_size==1), \"Sum of training, validation and test size needs to be 1!\"\n",
    "    assert(train_size * val_size * test_size > 0), \"Sizes have to be positive!\"\n",
    "    \n",
    "    #Check input_data type is numpy array, after casting\n",
    "    if type(input_data) != 'numpy.ndarray':\n",
    "        input_data = np.array(input_data) \n",
    "    \n",
    "    assert(isinstance(input_data, np.ndarray)), \"Input has to be a numpy array!\"\n",
    "    \n",
    "    \n",
    "    #Calculate cut-off points\n",
    "    train_cut_index = int(train_size * input_data.shape[0])\n",
    "    val_cut_index = train_cut_index + int(val_size * input_data.shape[0])\n",
    "    \n",
    "    #Split the data\n",
    "    if len(input_data.shape) == 1:\n",
    "        train, val, test = input_data[:train_cut_index], input_data[train_cut_index:val_cut_index], input_data[val_cut_index:]\n",
    "    else:\n",
    "        train, val, test = input_data[:train_cut_index,:], input_data[train_cut_index:val_cut_index, :], input_data[val_cut_index:, :]\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1738, 93)\n",
      "(372, 93)\n",
      "(373, 93)\n",
      "(1738, 2)\n",
      "(372, 2)\n",
      "(373, 2)\n"
     ]
    }
   ],
   "source": [
    "#------------\n",
    "#TEST OUTPUT\n",
    "#------------\n",
    "#Split data\n",
    "X_train, X_val, X_test = split_data(X, train_size=0.7, val_size=0.15, test_size=0.15)\n",
    "y_train, y_val, y_test = split_data(y, train_size=0.7, val_size=0.15, test_size=0.15)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to re-structure the data to get batches. Re-shape the data to have overlapping training set for time-series learning.\n",
    "def get_inputs_yield(input_data, labels, timesteps):\n",
    "    \n",
    "    #First get the total number of samples generated\n",
    "    n_seq = input_data.shape[0] - timesteps + 1\n",
    "    \n",
    "    #features, classes\n",
    "    n_dim = input_data.shape[1]\n",
    "    n_class = labels.shape[1]\n",
    "    \n",
    "    #Generate the sequences\n",
    "    for ii in range(0, n_seq):        \n",
    "        #Getting the overlapping samples\n",
    "        yield np.reshape(scale(input_data[ii:ii+timesteps, :]), (-1, timesteps, n_dim)), np.reshape(labels[ii:ii+timesteps, :], (-1, timesteps, n_class))         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to re-structure the data to get batches. Re-shape the data to have overlapping training set for time-series learning.\n",
    "def get_inputs(input_data, labels, batch_size, timesteps):\n",
    "    \n",
    "    #First get the total number of samples generated\n",
    "    n_seq = input_data.shape[0] - timesteps + 1\n",
    "    \n",
    "    #features, classes\n",
    "    n_dim = input_data.shape[1]\n",
    "    n_class = labels.shape[1]\n",
    "    \n",
    "    #Calculate the number of batches possible\n",
    "    n_samples = n_seq * timesteps\n",
    "    n_batches = n_samples // (batch_size * timesteps)\n",
    "\n",
    "    for jj in range(0, n_batches + 1):\n",
    "    #Generate the sequences\n",
    "        output = []\n",
    "        targets = []\n",
    "\n",
    "        #if jj == n_batches:\n",
    "            \n",
    "            #output.append([input_data[jj*batch_size:, :]])\n",
    "            #targets.append([labels[jj*batch_size:, :]])            \n",
    "            #yield np.vstack(output), np.vstack(targets  )\n",
    "            \n",
    "        #else:            \n",
    "        for ii in range(jj * batch_size, (jj + 1) * batch_size):                    \n",
    "            #Getting the overlapping samples\n",
    "            output.append([input_data[ii:ii + timesteps, :]])\n",
    "            targets.append([labels[ii:ii+timesteps, :]])\n",
    "\n",
    "        yield np.vstack(output), np.vstack(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:  (3, 4, 5)\n",
      "training: \n",
      " [[[ 1  2  3  4  5]\n",
      "  [ 6  7  8  9 10]\n",
      "  [11 12 13 14 15]\n",
      "  [16 17 18 19 20]]\n",
      "\n",
      " [[ 6  7  8  9 10]\n",
      "  [11 12 13 14 15]\n",
      "  [16 17 18 19 20]\n",
      "  [21 22 23 24 25]]\n",
      "\n",
      " [[11 12 13 14 15]\n",
      "  [16 17 18 19 20]\n",
      "  [21 22 23 24 25]\n",
      "  [26 27 28 29 30]]]\n",
      "label size:  (3, 4, 2)\n",
      "labels: \n",
      " [[[ 1  2]\n",
      "  [ 3  4]\n",
      "  [ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 3  4]\n",
      "  [ 5  6]\n",
      "  [ 7  8]\n",
      "  [ 9 10]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]\n",
      "  [ 9 10]\n",
      "  [11 12]]]\n",
      "training size:  (3, 4, 5)\n",
      "training: \n",
      " [[[16 17 18 19 20]\n",
      "  [21 22 23 24 25]\n",
      "  [26 27 28 29 30]\n",
      "  [31 32 33 34 35]]\n",
      "\n",
      " [[21 22 23 24 25]\n",
      "  [26 27 28 29 30]\n",
      "  [31 32 33 34 35]\n",
      "  [36 37 38 39 40]]\n",
      "\n",
      " [[26 27 28 29 30]\n",
      "  [31 32 33 34 35]\n",
      "  [36 37 38 39 40]\n",
      "  [41 42 43 44 45]]]\n",
      "label size:  (3, 4, 2)\n",
      "labels: \n",
      " [[[ 7  8]\n",
      "  [ 9 10]\n",
      "  [11 12]\n",
      "  [13 14]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]\n",
      "  [13 14]\n",
      "  [15 16]]\n",
      "\n",
      " [[11 12]\n",
      "  [13 14]\n",
      "  [15 16]\n",
      "  [17 18]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-3d37634c066a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training size: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-6d2a29fa6e1d>\u001b[0m in \u001b[0;36mget_inputs\u001b[1;34m(input_data, labels, batch_size, timesteps)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\bchik\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#------------\n",
    "#TEST OUTPUT\n",
    "#------------\n",
    "#get inputs\n",
    "t = np.reshape(np.arange(1,51), (10,5))\n",
    "s = np.reshape(np.arange(1,21), (10,2))\n",
    "\n",
    "for (x, y) in get_inputs(t,s, 3, 4):\n",
    "    print('training size: ', x.shape)\n",
    "    print('training: \\n', x)\n",
    "    print('label size: ', y.shape)\n",
    "    print('labels: \\n', y)\n",
    "    \n",
    "    \n",
    "\n",
    "#print(test_train[0:1])\n",
    "#print(test_label[0:1])\n",
    "#print(t)\n",
    "#print(test_train.shape)\n",
    "#print(test_label.shape)\n",
    "#print(test_train)\n",
    "#test_train.reshape((-1, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "n_dim = X.shape[1]\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_inputs() missing 1 required positional argument: 'timesteps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-8f3c4d80a8c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Normalize training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_val_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_inputs() missing 1 required positional argument: 'timesteps'"
     ]
    }
   ],
   "source": [
    "#Normalize training data\n",
    "X_train_np, y_train_np = get_inputs(X_train, y_train,timesteps)\n",
    "X_val_np, y_val_np = get_inputs(X_val, y_val, timesteps)\n",
    "X_test_np, y_test_np = get_inputs(X_test, y_test, timesteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(X_train_np))\n",
    "print(len(y_train_np))\n",
    "print(len(X_val_np))\n",
    "print(len(y_val_np))\n",
    "print(len(X_test_np))\n",
    "print(len(y_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train_np.shape)\n",
    "print(y_train_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = np.reshape(X_train_np, (-1, timesteps, n_dim))\n",
    "new_target = np.reshape(y_train_np, (-1, timesteps, n_classes))\n",
    "new_val_X = np.reshape(X_val_np, (-1, timesteps, n_dim))\n",
    "new_val_y = np.reshape(y_val_np, (-1, timesteps, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Parameters\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "loss = 'binary_crossentropy'\n",
    "dropout=0.5\n",
    "batch_size = 128\n",
    "timesteps = 200\n",
    "n_dim = X.shape[1]\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer = optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 200, 5)            1980      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200, 2)            12        \n",
      "=================================================================\n",
      "Total params: 1,992\n",
      "Trainable params: 1,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Architect\n",
    "#-----------------\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Stack LSTM Cells\n",
    "model.add(LSTM(5, input_shape=(timesteps, n_dim), return_sequences=True, stateful=False))\n",
    "\n",
    "#model.add(LSTM(50, return_sequences=True))\n",
    "\n",
    "#model.add(Dense(5, activation='relu'))\n",
    "\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n",
      "(128, 200, 93)\n",
      "(128, 200, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-27a2d24a70bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-123-6d2a29fa6e1d>\u001b[0m in \u001b[0;36mget_inputs\u001b[1;34m(input_data, labels, batch_size, timesteps)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\bchik\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "for (x,y) in get_inputs(X_train, y_train, batch_size, timesteps):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "#Fit\n",
    "#fitted = model.fit(new_train, new_target, epochs=epochs, \n",
    "                    #validation_data=(new_val_X, new_val_y), \n",
    "                    #batch_size=158, verbose=1, shuffle=False)\n",
    "\n",
    "#for e in range(epochs):\n",
    "    #print(\"Epoch %d\" %e)\n",
    "\n",
    "#    model.fit_generator(get_inputs(X_train, y_train, batch_size, timesteps), steps_per_epoch=batch_size, \n",
    "#                        epochs=epochs, verbose=1, validation_data=get_inputs(X_val, y_val, batch_size, timesteps), validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(get_inputs(X_test, y_test, timesteps), 1)\n",
    "model.predict_generator(get_inputs(X_test, y_test, timesteps), 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below this line are old codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 5: Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Plot Training vs Validation Curve\n",
    "plt.figure()\n",
    "plt.plot(fitted.history['loss'])\n",
    "plt.plot(fitted.history['val_loss'])\n",
    "plt.title('Training Loss & Validation Loss')\n",
    "plt.ylabel('Binary Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Plot Training vs Validation Accuracy\n",
    "plt.figure()\n",
    "plt.plot(fitted.history['acc'])\n",
    "plt.plot(fitted.history['val_acc'])\n",
    "plt.title('Training Accuracy & Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
